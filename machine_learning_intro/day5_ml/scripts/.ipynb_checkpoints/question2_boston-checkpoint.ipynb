{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習問題2 回帰 (Normal)\n",
    "\n",
    "## 問題\n",
    "以下の13個の変数からその地域の住宅価格の中央値(MEDV)を推測することができる回帰モデルを作成せよ.\n",
    "1. CRIM\t人口 1 人当たりの犯罪発生数\n",
    "2. ZN\t25,000 平方フィート以上の住居区画の占める割合\n",
    "3. INDUS\t小売業以外の商業が占める面積の割合\n",
    "4. CHAS\tチャールズ川によるダミー変数 (1: 川の周辺, 0: それ以外)\n",
    "5. NOX\tNOx の濃度\n",
    "6. RM\t住居の平均部屋数\n",
    "7. AGE\t1940 年より前に建てられた物件の割合\n",
    "8. DIS\t5 つのボストン市の雇用施設からの距離 (重み付け済)\n",
    "9. RAD\t環状高速道路へのアクセスしやすさ\n",
    "10. TAX\t10,000 ドルあたりの不動産税率の総計\n",
    "11. PTRATIO\t町毎の児童と教師の比率\n",
    "12. B\t町毎の黒人 (Bk) の比率を次の式で表したもの。 1000(Bk – 0.63)^2\n",
    "13. LSTAT\t給与の低い職業に従事する人口の割合 (%)\n",
    "\n",
    "#### ヒント　\n",
    "手順は以下の順番でおこなうとよい.\n",
    "\n",
    "1. 欠損値があるかを確認する.\n",
    "2. データを見て, どのアルゴリズムを使うかを決める.\n",
    "3. ハイパーパラメータの最適化を行う.\n",
    "\n",
    "(2と3は同時平行に行なってもよい.)\n",
    "\n",
    "結局は、分類問題と回帰問題の違いはクラスを予測するか値を予測するかの違いのみである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "#扱いづらいので, dataframe型のインターフェイスにする.\n",
    "boston_df = pd.DataFrame(boston.data)\n",
    "boston_df.columns = boston.feature_names\n",
    "#今回の演習の目的変数に相当\n",
    "boston_df[\"MEDV\"] =  boston.target\n",
    "#データの最初の5行を表示\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠損値があるかどうかを調べる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boston_df.isnull().sum()#欠損値数の和を出力."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各変数の相関値を表示する. ここで, 目的変数との相関値が低い説明変数を選択しても意味はないどころか, 悪影響を及ぼす場合があるので注意する. しかし, 目視で変数選択をするの難しいため, Lasso回帰やAICを用いて変数選択するのがよい."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df.corr() #各列の相関値を調べる."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 線形回帰\n",
    "\n",
    "まずは線形回帰(Lasso)を使ってみる."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso#lasso回帰を用いる.\n",
    "\n",
    "rgs = Lasso(normalize=True)#ハイパーパラメータ設定\n",
    "\n",
    "X_boston = boston_df.iloc[:,:13]#説明変数を格納\n",
    "y_boston = boston_df.iloc[:,13]#目的変数を格納\n",
    "\n",
    "params3 = {\"alpha\":[0, 0.001, 0.01,0.1, 1],\"random_state\":[0] }\n",
    "cv_3 = GridSearchCV(rgs, params3, cv = 20 , n_jobs =-1,scoring= \"neg_mean_squared_error\")\n",
    "cv_3.fit(X_boston, y_boston )\n",
    "print(\"計算完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " sklearnの場合, すべての評価指標はより高い値が低い値よりも優れている という規則に従うため、\n",
    "MSE等の低い値が優れているとされている指標には-1をかけて負の数をして扱う."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_3.cv_results_[\"mean_test_score\"] #Lasso回帰の結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"最適なハイパーパラメータは {}です\".format(cv_3.best_params_))\n",
    "print(\"回帰係数は{}です.\".format(cv_3.best_estimator_.coef_))\n",
    "print(\"切片は{}です.\".format(cv_3.best_estimator_.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非線形回帰分析\n",
    "\n",
    "多項式回帰を用いて、非線形な回帰モデルを作成する."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# 2乗したデータまでを格納\n",
    "quadratic  = PolynomialFeatures(degree = 2)\n",
    "X_quadratic_boston = quadratic.fit_transform(X_boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params4 = {\"alpha\":[0, 0.001,0.01,0.1,1],\"random_state\":[0] }\n",
    "cv_4 = GridSearchCV(rgs, params4, cv = 20 , n_jobs =-1,scoring= \"neg_mean_squared_error\")\n",
    "cv_4.fit(X_quadratic_boston , y_boston )\n",
    "cv_4.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_4.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"最適なハイパーパラメータは {}です\".format(cv_4.best_params_))\n",
    "print(\"回帰係数は{}です.\".format(cv_4.best_estimator_.coef_))\n",
    "print(\"切片は{}です.\".format(cv_4.best_estimator_.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_boston, cv_4.predict(X_quadratic_boston))\n",
    "plt.plot(y_boston, y_boston, color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### まとめ\n",
    "非線形回帰分析の方が表現力があがるため, 誤差の少ないモデルを構築することができた. \n",
    "今回は2次元までの多項式回帰を用いたが,　次元数を大きくし過ぎると過学習がおこり, 汎化性能はむしろ下がってしまうので注意."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
